import Bull from 'bull';
import { scrapeMetaAds } from '../scrapers/metaAdLibrary.js';
import { updateJobStatus } from '../services/dbService.js';
import { supabase } from '../config/supabase.js';

export const scrapeQueue = new Bull('meta-ads-scrape', {
  redis: {
    host: process.env.REDIS_HOST || 'localhost',
    port: parseInt(process.env.REDIS_PORT) || 6379,
    password: process.env.REDIS_PASSWORD || undefined,
    tls: process.env.REDIS_TLS === 'true' ? {} : undefined
  }
});

export async function addScrapeJob({ searchType, searchQuery, platform = 'meta', maxAds = 100 }) {
  const job = await scrapeQueue.add(
    {
      searchType,
      searchQuery,
      platform,
      maxAds
    },
    {
      attempts: 3,
      backoff: {
        type: 'exponential',
        delay: 60000
      },
      timeout: 900000 // 15ë¶„ (Cloudinary ì—…ë¡œë“œ ì‹œê°„ ê³ ë ¤)
    }
  );

  return job.id.toString();
}

scrapeQueue.process(async (job) => {
  const { searchType, searchQuery, platform, maxAds } = job.data;
  const jobId = job.id.toString();

  console.log(`\nðŸš€ Starting scrape job ${jobId} for "${searchQuery}"`);
  console.log(`   Search Type: ${searchType}`);
  console.log(`   Max Ads: ${maxAds}`);

  try {
    await updateJobStatus(jobId, 'processing');

    // ì§„í–‰ë¥  ì½œë°±
    const onProgress = (progress) => {
      job.progress(progress);
      console.log(`ðŸ“Š Progress: ${progress}%`);
    };

    // ë©”íƒ€ ê´‘ê³  ìŠ¤í¬ëž˜í•‘ (Cloudinary ìžë™ ì—…ë¡œë“œ)
    const result = await scrapeMetaAds({
      searchType,
      searchQuery,
      maxAds,
      country: 'KR',
      onProgress,
      uploadToCloudinary: true, // Cloudinary ìžë™ ì—…ë¡œë“œ
      headless: false // ë¸Œë¼ìš°ì € í‘œì‹œ (ë””ë²„ê¹…ìš©)
    });

    const savedCount = result.savedAds || 0;
    const newCount = result.newAds || 0;
    const updatedCount = result.updatedAds || 0;
    const failedCount = result.failedAds || 0;

    console.log(`âœ… Scraping completed!`);
    console.log(`   New: ${newCount}`);
    console.log(`   Updated: ${updatedCount}`);
    if (failedCount > 0) {
      console.log(`   Failed: ${failedCount}`);
    }

    // Job ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
    await updateJobStatus(jobId, 'completed', savedCount);
    console.log(`âœ… Job ${jobId} completed: ${newCount} new, ${updatedCount} updated${failedCount > 0 ? `, ${failedCount} failed` : ''}\n`);

    return {
      totalAds: savedCount,
      newAds: newCount,
      updatedAds: updatedCount,
      failedAds: failedCount
    };

  } catch (error) {
    console.error(`âŒ Job ${jobId} failed:`, error);
    await updateJobStatus(jobId, 'failed');
    throw error;
  }
});

scrapeQueue.on('completed', (job, result) => {
  const summary = `${result.newAds || 0} new, ${result.updatedAds || 0} updated`;
  const failed = result.failedAds > 0 ? `, ${result.failedAds} failed` : '';
  console.log(`âœ… Job ${job.id} completed: ${summary}${failed}`);
});

scrapeQueue.on('failed', (job, err) => {
  console.error(`âŒ Job ${job.id} failed:`, err.message);
});

// Redis ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
scrapeQueue.on('error', (error) => {
  console.error('âŒ Redis connection error:', error.message);
});

scrapeQueue.on('ready', () => {
  console.log('âœ… Redis connected successfully - Queue ready');
});
